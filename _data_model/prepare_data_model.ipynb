{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data and build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements\n",
    "!pip install -r requirements.txt\n",
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import fatf_dash.census as census\n",
    "from fatf_dash.census import census_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-22 20:19:37--  http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3974305 (3.8M) [application/x-httpd-php]\n",
      "Saving to: ‘adult.data’\n",
      "\n",
      "adult.data          100%[===================>]   3.79M   163KB/s    in 18s     \n",
      "\n",
      "2022-03-22 20:19:55 (219 KB/s) - ‘adult.data’ saved [3974305/3974305]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download census\n",
    "! wget http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
    "# ! wget http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\n",
    "# ! wget http://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\n",
    "# ! wget http://archive.ics.uci.edu/ml/machine-learning-databases/adult/old.adult.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv(\n",
    "    'adult.data',\n",
    "    names=census_names,\n",
    "    skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kacper/.pyenv/versions/3.7.9/envs/heroku/lib/python3.7/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "age               False\n",
       "workclass          True\n",
       "fnlwgt            False\n",
       "education         False\n",
       "education-num     False\n",
       "marital-status    False\n",
       "occupation         True\n",
       "relationship      False\n",
       "race              False\n",
       "sex               False\n",
       "capital-gain      False\n",
       "capital-loss      False\n",
       "hours-per-week    False\n",
       "native-country     True\n",
       "income            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "(df == '?').any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing data points\n",
    "workclass_missing = df.index[df['workclass'] == '?'].tolist()\n",
    "occupation_missing = df.index[df['occupation'] == '?'].tolist()\n",
    "native_country_missing = df.index[df['native-country'] == '?'].tolist()\n",
    "\n",
    "all_missing = set(workclass_missing).union(occupation_missing).union(native_country_missing)\n",
    "\n",
    "df.drop(all_missing, inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               False\n",
       "workclass         False\n",
       "fnlwgt            False\n",
       "education         False\n",
       "education-num     False\n",
       "marital-status    False\n",
       "occupation        False\n",
       "relationship      False\n",
       "race              False\n",
       "sex               False\n",
       "capital-gain      False\n",
       "capital-loss      False\n",
       "hours-per-week    False\n",
       "native-country    False\n",
       "income            False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing, again\n",
    "(df == '?').any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                int64\n",
       "workclass         object\n",
       "fnlwgt             int64\n",
       "education         object\n",
       "education-num      int64\n",
       "marital-status    object\n",
       "occupation        object\n",
       "relationship      object\n",
       "race              object\n",
       "sex               object\n",
       "capital-gain       int64\n",
       "capital-loss       int64\n",
       "hours-per-week     int64\n",
       "native-country    object\n",
       "income            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display feature types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique feature values\n",
    "features_unique = {\n",
    "    'workclass': np.sort(df['workclass'].unique()),\n",
    "    'education': np.sort(df['education'].unique()),\n",
    "    'marital-status': np.sort(df['marital-status'].unique()),\n",
    "    'occupation': np.sort(df['occupation'].unique()),\n",
    "    'relationship': np.sort(df['relationship'].unique()),\n",
    "    'race': np.sort(df['race'].unique()),\n",
    "    'sex': np.sort(df['sex'].unique()),\n",
    "    'native-country': np.sort(df['native-country'].unique()),\n",
    "    'income': np.sort(df['income'].unique())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature mappings in both directions\n",
    "map_i_s = {}\n",
    "map_s_i = {}\n",
    "for feature_name in features_unique:\n",
    "    map_i_s[feature_name] = dict()\n",
    "    map_s_i[feature_name] = dict()\n",
    "    for i, value in enumerate(features_unique[feature_name]):\n",
    "        map_i_s[feature_name][i] = value\n",
    "        map_s_i[feature_name][value] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that these are still up to date\n",
    "def dict_comp(d1, d2):\n",
    "    d1_keys, d2_keys = sorted(list(d1)), sorted(list(d2))\n",
    "    assert len(d1_keys) == len(d2_keys)\n",
    "    for i, j in zip(d1_keys, d2_keys):\n",
    "        assert i == j\n",
    "        d1_i_keys, d2_j_keys = sorted(list(d1[i])), sorted(list(d2[j]))\n",
    "        assert len(d1_i_keys) == len(d2_j_keys)\n",
    "        for ii, jj in zip(d1_i_keys, d2_j_keys):\n",
    "            assert ii == jj\n",
    "            assert d1[i][ii] == d2[j][jj]\n",
    "\n",
    "dict_comp(census.map_i_s, map_i_s)\n",
    "dict_comp(census.map_s_i, map_s_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map all of the string features to integer, making the data set numerical\n",
    "for feature_name in map_s_i:\n",
    "    df[feature_name] = df[feature_name].map(map_s_i[feature_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               int64\n",
       "workclass         int64\n",
       "fnlwgt            int64\n",
       "education         int64\n",
       "education-num     int64\n",
       "marital-status    int64\n",
       "occupation        int64\n",
       "relationship      int64\n",
       "race              int64\n",
       "sex               int64\n",
       "capital-gain      int64\n",
       "capital-loss      int64\n",
       "hours-per-week    int64\n",
       "native-country    int64\n",
       "income            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ground truth from the data set\n",
    "array = df.drop('income', axis=1).values\n",
    "ground_truth = df['income'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit logistic regression\n",
    "clf = sklearn.linear_model.LogisticRegression(solver='lbfgs')\n",
    "clf.fit(array, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7840660433658245"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check training set accuracy\n",
    "train_predict = clf.predict(array)\n",
    "sklearn.metrics.accuracy_score(ground_truth, train_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['log_reg.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the data, ground truth and model\n",
    "np.save('adult_num.pkl', array)\n",
    "np.save('adult_num_gt.pkl', ground_truth)\n",
    "joblib.dump(clf, 'log_reg.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
